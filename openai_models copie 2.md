# OpenAI Model Documentation

This document summarizes key information about various OpenAI models. Prices are per 1 million tokens.

---

## gpt-4o-mini-2025-04-16

*   **Context Window:** 200,000 tokens
*   **Max Output Tokens:** 100,000 tokens
*   **Knowledge Cutoff:** Jun 01, 2024
*   **Supported Features:**
    *   Structured Outputs: Yes
    *   Function Calling: Yes

---

## gpt-4.1-2025-04-14

*   **Price (Input/Output):** $2 / $8 per 1M tokens
*   **Reasoning Token Price (Input/Output):** $1.1 / $4.4 per 1M tokens
*   **Context Window:** 1,047,576 tokens
*   **Max Output Tokens:** 32,768 tokens
*   **Knowledge Cutoff:** Jun 01, 2024
*   **Supported Features:**
    *   Streaming: Yes
    *   Function Calling: Yes
    *   Structured Outputs: Yes
    *   Fine-tuning: Yes
    *   Distillation: Yes
    *   Predicted Outputs: Yes
    *   Reasoning token support: Yes

---

## gpt-4o-2024-08-06

*   **Price (Input/Output):** $2.5 / $10 per 1M tokens
*   **Supported Features:**
    *   Streaming: Yes
    *   Function Calling: Yes
    *   Structured Outputs: Yes
    *   Fine-tuning: Yes
    *   Distillation: Yes
    *   Predicted Outputs: Yes

---

## gpt-4.1-mini-2025-04-14

*   **Price (Input/Output):** $0.4 / $1.6 per 1M tokens
*   **Context Window:** 1,047,576 tokens
*   **Max Output Tokens:** 32,768 tokens
*   **Knowledge Cutoff:** Jun 01, 2024
*   **Supported Features:**
    *   Streaming: Yes
    *   Function Calling: Yes
    *   Structured Outputs: Yes
    *   Fine-tuning: Yes

---

## o3-mini-2025-01-31

*   **Description:** Newest small reasoning model, high intelligence at the same cost/latency as o1-mini.
*   **Price (Input/Output):** $1.1 / $4.4 per 1M tokens
*   **Context Window:** 200,000 tokens
*   **Max Output Tokens:** 100,000 tokens
*   **Knowledge Cutoff:** Oct 01, 2023
*   **Supported Features:**
    *   Reasoning token support: Yes
    *   Streaming: Yes
    *   Function Calling: Yes
    *   Structured Outputs: Yes
    *   Batch API: Yes

---

## o1-mini-2024-09-12

*   **Description:** Small model alternative to o1. Recommended to use o3-mini instead.
*   **Reasoning:** High
*   **Speed:** Slow
*   **Price (Input/Output):** $1.1 / $4.4 per 1M tokens
*   **Input/Output Type:** Text / Text
*   **Context Window:** 128,000 tokens
*   **Max Output Tokens:** 65,536 tokens
*   **Knowledge Cutoff:** Oct 01, 2023
*   **Supported Features:**
    *   Reasoning token support: Yes
    *   Streaming: Yes

--- 